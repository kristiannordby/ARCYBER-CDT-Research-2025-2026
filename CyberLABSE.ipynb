{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9112d5ff-60e3-41f4-b407-2b7a209354a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import random \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e80b80-604b-4a5a-a3a1-6e8196d7aa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Models will be saved to: /home/knordby/Documents/labeling/models\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "models_dir = \"/home/knordby/Documents/labeling/models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "print(f\"\\nüìÅ Models will be saved to: {models_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502e273f-b249-4b55-9680-8b68ce8539bd",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "Here we load our embeddings and as well as our presaved labels for each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b963ac1-3ffa-4079-9a0d-fd87f0cb2267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/4] Loading embeddings...\n",
      "   Loading general_sample_200K embeddings...\n",
      "   Loaded 199793 embeddings from 200K dataset\n",
      "   Loading cyber_biased_sample_70K embeddings...\n",
      "   Loaded 62605 embeddings from 70K dataset\n",
      "   Total embeddings after merge: 262398\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[1/4] Loading embeddings...\")\n",
    "\n",
    "# Load 200K general embeddings\n",
    "print(\"   Loading general_sample_200K embeddings...\")\n",
    "with gzip.open('general_sample_200K_embedding_labse.jsonl.gz', 'rt') as f:\n",
    "    _200k_embeddings = json.load(f)\n",
    "_200k_embeddings = {k.replace('.json', ''): v for k, v in _200k_embeddings.items()}\n",
    "print(f\"   Loaded {len(_200k_embeddings)} embeddings from 200K dataset\")\n",
    "\n",
    "# Load 70K cyber-biased embeddings\n",
    "print(\"   Loading cyber_biased_sample_70K embeddings...\")\n",
    "with gzip.open('cyber_biased_sample_70K_labse_embedding.jsonl.gz', 'rt') as f:\n",
    "    _70k_embeddings = json.load(f)\n",
    "_70k_embeddings = {k.replace('.json', ''): v for k, v in _70k_embeddings.items()}\n",
    "print(f\"   Loaded {len(_70k_embeddings)} embeddings from 70K dataset\")\n",
    "\n",
    "# Merge embeddings\n",
    "labse_embeddings = _70k_embeddings | _200k_embeddings\n",
    "print(f\"   Total embeddings after merge: {len(labse_embeddings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90245f20-97e0-42ba-9cbc-04c78f7bcc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 178 ms, sys: 28.2 ms, total: 207 ms\n",
      "Wall time: 205 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = np.load('datasets/cyber_gemma_embeddings_with_ids.npz')\n",
    "ids = data['ids']\n",
    "labels = data['labels'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd156af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"english_ids.txt\", \"r\") as f:\n",
    "    english_ids = f.read().splitlines()\n",
    "english_ids_set = set(english_ids)\n",
    "with open(\"nonenglish_ids.txt\", \"r\") as f:\n",
    "    nonenglish_ids = f.read().splitlines()\n",
    "nonenglish_ids_set = set(nonenglish_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d248341-e1c9-4418-8035-1ed4215e9b65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings = [labse_embeddings[idx] for idx in ids]\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c881f9e-7d07-45ad-9edb-473829e36791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207990, 207990, 207990)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings), len(ids), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0587ae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_mask = np.array([id_ in english_ids_set for id_ in ids])\n",
    "nonenglish_mask = np.array([id_ in nonenglish_ids_set for id_ in ids])\n",
    "\n",
    "english_embeddings = embeddings[english_mask]\n",
    "nonenglish_embeddings = embeddings[nonenglish_mask]\n",
    "english_labels = labels[english_mask]\n",
    "nonenglish_labels = labels[nonenglish_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61ed063-23c2-4919-8a3b-1a296f067290",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b8a065-adc1-4acd-ab7a-9976172f4512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/4] Preparing train/test split...\n",
      "x_train:  0.7999912733438054\n",
      "test size:  0.20000872665619468\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "print(\"\\n[3/4] Preparing train/test split...\")\n",
    "\n",
    "# x_train_ids,x_test_ids, y_train,y_test = train_test_split(ids, labels, train_size = 0.8, stratify = labels)\n",
    "english_xtrain, english_xtest, english_ytrain, english_ytest = train_test_split(\n",
    "    english_embeddings, english_labels, train_size=0.8, stratify=english_labels, random_state=42)\n",
    "nonenglish_xtrain, nonenglish_xtest, nonenglish_ytrain, nonenglish_ytest = train_test_split(\n",
    "    nonenglish_embeddings, nonenglish_labels, train_size=0.8, stratify=nonenglish_labels, random_state=42)\n",
    "\n",
    "x_train = np.concatenate([english_xtrain, nonenglish_xtrain], axis=0)\n",
    "y_train =  np.concatenate([english_ytrain, nonenglish_ytrain], axis=0)\n",
    "x_test = np.concatenate([english_xtest, nonenglish_xtest], axis=0)\n",
    "y_test =  np.concatenate([english_ytest, nonenglish_ytest], axis=0)\n",
    "\n",
    "print(\"x_train: \", len(x_train)/(len(x_train)+len(x_test)))\n",
    "print(\"test size: \", len(x_test)/(len(x_train)+len(x_test)))\n",
    "\n",
    "\n",
    "val_split_idx = int(len(x_train)*.85)\n",
    "x_val, y_val = x_train[val_split_idx:], y_train[val_split_idx:]\n",
    "x_train, y_train = x_train[:val_split_idx], y_train[:val_split_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e8ac8-e22c-4144-a79f-f74d461d88ed",
   "metadata": {},
   "source": [
    "#### Dataset Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7888c8cd-df43-4378-8599-56c031dcb9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Dataset Statistics:\n",
      "   Training set shape: (109089, 768)\n",
      "   Test set shape: (32087, 768)\n",
      "   Embedding dimension: 768\n",
      "\n",
      "   Label Distribution:\n",
      "   ‚Ä¢ Training - Cyber: 5358 (4.9%)\n",
      "   ‚Ä¢ Training - Non-cyber: 103731 (95.1%)\n",
      "   ‚Ä¢ Test - Cyber: 1517 (4.7%)\n",
      "   ‚Ä¢ Test - Non-cyber: 30570 (95.3%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"Training set shape: {x_train.shape}\")\n",
    "print(f\"Test set shape: {x_test.shape}\")\n",
    "print(f\"Embedding dimension: {x_train.shape[1]}\")\n",
    "print(f\"\\nLabel Distribution:\")\n",
    "print(f\"Training - Cyber: {sum(y_train)} ({sum(y_train)/len(y_train)*100:.1f}%)\")\n",
    "print(f\"Training - Non-cyber: {len(y_train)-sum(y_train)} ({(len(y_train)-sum(y_train))/len(y_train)*100:.1f}%)\")\n",
    "print(f\"Test - Cyber: {sum(y_test)} ({sum(y_test)/len(y_test)*100:.1f}%)\")\n",
    "print(f\"Test - Non-cyber: {len(y_test)-sum(y_test)} ({(len(y_test)-sum(y_test))/len(y_test)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a6ba0a-274b-4de3-af75-66332a9ad399",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7020d7af-30dd-4f35-8028-a3eccfd9fa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "======================================================================\n",
      "MODEL BUILT\n",
      "======================================================================\n",
      "Architecture: CyberClassifier\n",
      "Input dimension: 768\n",
      "Hidden layers: 512 -> 256 -> 128\n",
      "Output: 1 (binary classification)\n",
      "Total parameters: 561,409\n",
      "Trainable parameters: 561,409\n",
      "Device: cuda\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_models import *\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Build model\n",
    "model, optimizer, criterion = build_model(\n",
    "    input_dim=x_train.shape[1],  # Auto-detect from your data\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ddf9bdd-4c58-4be8-a07c-dfdbabb9ff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Using standard shuffling for training\n",
      "======================================================================\n",
      "TRAINING\n",
      "======================================================================\n",
      "Epochs: 80\n",
      "Batch size: 512\n",
      "Training samples: 109089\n",
      "Validation samples: 32087\n",
      "Early stopping patience: 15\n",
      "======================================================================\n",
      "\n",
      "Epoch 1/80 - Time: 5.49s\n",
      "  Train - Loss: 0.1350, Acc: 0.9579, AUC: 0.8971\n",
      "  Val   - Loss: 0.1085, Acc: 0.9626, AUC: 0.9282, Precision: 0.7018, Recall: 0.3645\n",
      "  ‚úì Best model saved (AUC: 0.9282)\n",
      "\n",
      "Epoch 2/80 - Time: 2.37s\n",
      "  Train - Loss: 0.0933, Acc: 0.9651, AUC: 0.9578\n",
      "  Val   - Loss: 0.1062, Acc: 0.9629, AUC: 0.9345, Precision: 0.6667, Recall: 0.4298\n",
      "  ‚úì Best model saved (AUC: 0.9345)\n",
      "\n",
      "Epoch 3/80 - Time: 2.15s\n",
      "  Train - Loss: 0.0790, Acc: 0.9699, AUC: 0.9732\n",
      "  Val   - Loss: 0.1095, Acc: 0.9627, AUC: 0.9299, Precision: 0.6782, Recall: 0.4001\n",
      "  No improvement (patience: 1/15)\n",
      "\n",
      "Epoch 4/80 - Time: 2.14s\n",
      "  Train - Loss: 0.0653, Acc: 0.9744, AUC: 0.9832\n",
      "  Val   - Loss: 0.1142, Acc: 0.9621, AUC: 0.9287, Precision: 0.6342, Recall: 0.4674\n",
      "  No improvement (patience: 2/15)\n",
      "\n",
      "Epoch 5/80 - Time: 4.97s\n",
      "  Train - Loss: 0.0516, Acc: 0.9804, AUC: 0.9905\n",
      "  Val   - Loss: 0.1269, Acc: 0.9615, AUC: 0.9203, Precision: 0.6484, Recall: 0.4061\n",
      "  No improvement (patience: 3/15)\n",
      "\n",
      "Epoch 6/80 - Time: 2.48s\n",
      "  Train - Loss: 0.0398, Acc: 0.9853, AUC: 0.9949\n",
      "  Val   - Loss: 0.1418, Acc: 0.9597, AUC: 0.9135, Precision: 0.5955, Recall: 0.4581\n",
      "  No improvement (patience: 4/15)\n",
      "\n",
      "Epoch 7/80 - Time: 2.47s\n",
      "  Train - Loss: 0.0322, Acc: 0.9885, AUC: 0.9966\n",
      "  Val   - Loss: 0.1570, Acc: 0.9605, AUC: 0.9166, Precision: 0.6270, Recall: 0.4034\n",
      "  No improvement (patience: 5/15)\n",
      "\n",
      "Epoch 8/80 - Time: 4.69s\n",
      "  Train - Loss: 0.0249, Acc: 0.9914, AUC: 0.9980\n",
      "  Val   - Loss: 0.1636, Acc: 0.9591, AUC: 0.9086, Precision: 0.6010, Recall: 0.4021\n",
      "  No improvement (patience: 6/15)\n",
      "\n",
      "Epoch 9/80 - Time: 2.48s\n",
      "  Train - Loss: 0.0106, Acc: 0.9973, AUC: 0.9998\n",
      "  Val   - Loss: 0.1727, Acc: 0.9615, AUC: 0.9100, Precision: 0.6431, Recall: 0.4192\n",
      "  No improvement (patience: 7/15)\n",
      "\n",
      "Epoch 10/80 - Time: 4.71s\n",
      "  Train - Loss: 0.0055, Acc: 0.9989, AUC: 0.9999\n",
      "  Val   - Loss: 0.1923, Acc: 0.9616, AUC: 0.9075, Precision: 0.6404, Recall: 0.4285\n",
      "  No improvement (patience: 8/15)\n",
      "\n",
      "Epoch 11/80 - Time: 2.51s\n",
      "  Train - Loss: 0.0067, Acc: 0.9985, AUC: 0.9998\n",
      "  Val   - Loss: 0.1909, Acc: 0.9608, AUC: 0.9054, Precision: 0.6127, Recall: 0.4641\n",
      "  No improvement (patience: 9/15)\n",
      "\n",
      "Epoch 12/80 - Time: 2.19s\n",
      "  Train - Loss: 0.0036, Acc: 0.9993, AUC: 0.9999\n",
      "  Val   - Loss: 0.1985, Acc: 0.9613, AUC: 0.9028, Precision: 0.6335, Recall: 0.4318\n",
      "  No improvement (patience: 10/15)\n",
      "\n",
      "Epoch 13/80 - Time: 2.13s\n",
      "  Train - Loss: 0.0023, Acc: 0.9996, AUC: 1.0000\n",
      "  Val   - Loss: 0.2087, Acc: 0.9603, AUC: 0.9040, Precision: 0.6050, Recall: 0.4595\n",
      "  No improvement (patience: 11/15)\n",
      "\n",
      "Epoch 14/80 - Time: 2.41s\n",
      "  Train - Loss: 0.0020, Acc: 0.9997, AUC: 0.9999\n",
      "  Val   - Loss: 0.2139, Acc: 0.9611, AUC: 0.8993, Precision: 0.6196, Recall: 0.4595\n",
      "  No improvement (patience: 12/15)\n",
      "\n",
      "Epoch 15/80 - Time: 5.27s\n",
      "  Train - Loss: 0.0013, Acc: 0.9998, AUC: 1.0000\n",
      "  Val   - Loss: 0.2190, Acc: 0.9614, AUC: 0.8981, Precision: 0.6330, Recall: 0.4377\n",
      "  No improvement (patience: 13/15)\n",
      "\n",
      "Epoch 16/80 - Time: 2.51s\n",
      "  Train - Loss: 0.0009, Acc: 0.9999, AUC: 1.0000\n",
      "  Val   - Loss: 0.2213, Acc: 0.9608, AUC: 0.8971, Precision: 0.6222, Recall: 0.4364\n",
      "  No improvement (patience: 14/15)\n",
      "\n",
      "Epoch 17/80 - Time: 2.57s\n",
      "  Train - Loss: 0.0008, Acc: 0.9999, AUC: 1.0000\n",
      "  Val   - Loss: 0.2224, Acc: 0.9606, AUC: 0.8988, Precision: 0.6097, Recall: 0.4654\n",
      "  No improvement (patience: 15/15)\n",
      "\n",
      "‚ö†Ô∏è  Early stopping triggered after 17 epochs\n",
      "\n",
      "======================================================================\n",
      "Loading best model...\n",
      "‚úÖ Best model loaded (AUC: 0.9345)\n",
      "üíæ Model saved to: /home/knordby/Documents/labeling/models/cyber_labseEmbeddings.pt\n",
      "‚è±Ô∏è  Total training time: 53.62s (0.89m)\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set save path\n",
    "model_path = '/home/knordby/Documents/labeling/models/cyber_labseEmbeddings.pt'\n",
    "\n",
    "# Train\n",
    "model, history = train_model(\n",
    "    model, optimizer, criterion,\n",
    "    x_train, y_train, x_test, y_test,\n",
    "    device=device,\n",
    "    epochs=80,\n",
    "    batch_size=512,\n",
    "    model_path=model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736256f5-1fa1-4b37-b4da-5f38e6a9e9d6",
   "metadata": {},
   "source": [
    "### Evaluate the Model's Performance Against the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8785f05",
   "metadata": {},
   "source": [
    "#### Holistic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1d5e970-c4b7-4218-bf64-c23414e4bc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìà CYBERSECURITY CLASSIFIER - FINAL TEST RESULTS\n",
      "======================================================================\n",
      "   Loss:      0.1061\n",
      "   Accuracy:  0.9629 (96.29%)\n",
      "   Precision: 0.6667\n",
      "   Recall:    0.4298\n",
      "   AUC:       0.9345\n",
      "   F1 Score:  0.5226\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "                 Negative  Positive\n",
      "Actual Negative     30244       326\n",
      "       Positive       865       652\n",
      "\n",
      "Detailed Metrics:\n",
      "   True Positives:  652\n",
      "   True Negatives:  30244\n",
      "   False Positives: 326\n",
      "   False Negatives: 865\n",
      "   Specificity:     0.9893\n",
      "   NPV:             0.9722\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Cyber     0.9722    0.9893    0.9807     30570\n",
      "       Cyber     0.6667    0.4298    0.5226      1517\n",
      "\n",
      "    accuracy                         0.9629     32087\n",
      "   macro avg     0.8194    0.7096    0.7517     32087\n",
      "weighted avg     0.9577    0.9629    0.9590     32087\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Test AUC: 0.9345\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with detailed metrics\n",
    "y_pred_probs, metrics = evaluate_model(\n",
    "    model, x_test, y_test,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Access individual metrics if needed\n",
    "print(f\"Test AUC: {metrics['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3d100",
   "metadata": {},
   "source": [
    "#### English Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d625343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìà CYBERSECURITY CLASSIFIER - FINAL TEST RESULTS\n",
      "======================================================================\n",
      "   Loss:      0.1473\n",
      "   Accuracy:  0.9482 (94.82%)\n",
      "   Precision: 0.7373\n",
      "   Recall:    0.4117\n",
      "   AUC:       0.9194\n",
      "   F1 Score:  0.5283\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "                 Negative  Positive\n",
      "Actual Negative      8710        98\n",
      "       Positive       393       275\n",
      "\n",
      "Detailed Metrics:\n",
      "   True Positives:  275\n",
      "   True Negatives:  8710\n",
      "   False Positives: 98\n",
      "   False Negatives: 393\n",
      "   Specificity:     0.9889\n",
      "   NPV:             0.9568\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Cyber     0.9568    0.9889    0.9726      8808\n",
      "       Cyber     0.7373    0.4117    0.5283       668\n",
      "\n",
      "    accuracy                         0.9482      9476\n",
      "   macro avg     0.8470    0.7003    0.7505      9476\n",
      "weighted avg     0.9413    0.9482    0.9413      9476\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Test AUC: 0.9194\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with detailed metrics\n",
    "y_pred_probs, metrics = evaluate_model(\n",
    "    model, english_xtest, english_ytest,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Access individual metrics if needed\n",
    "print(f\"Test AUC: {metrics['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e609339d",
   "metadata": {},
   "source": [
    "#### Non-English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "947ad05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìà CYBERSECURITY CLASSIFIER - FINAL TEST RESULTS\n",
      "======================================================================\n",
      "   Loss:      0.0889\n",
      "   Accuracy:  0.9690 (96.90%)\n",
      "   Precision: 0.6231\n",
      "   Recall:    0.4441\n",
      "   AUC:       0.9392\n",
      "   F1 Score:  0.5186\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "                 Negative  Positive\n",
      "Actual Negative     21534       228\n",
      "       Positive       472       377\n",
      "\n",
      "Detailed Metrics:\n",
      "   True Positives:  377\n",
      "   True Negatives:  21534\n",
      "   False Positives: 228\n",
      "   False Negatives: 472\n",
      "   Specificity:     0.9895\n",
      "   NPV:             0.9786\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Cyber     0.9786    0.9895    0.9840     21762\n",
      "       Cyber     0.6231    0.4441    0.5186       849\n",
      "\n",
      "    accuracy                         0.9690     22611\n",
      "   macro avg     0.8008    0.7168    0.7513     22611\n",
      "weighted avg     0.9652    0.9690    0.9665     22611\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Test AUC: 0.9392\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with detailed metrics\n",
    "y_pred_probs, metrics = evaluate_model(\n",
    "    model, nonenglish_xtest, nonenglish_ytest,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Access individual metrics if needed\n",
    "print(f\"Test AUC: {metrics['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ddbc6-372a-4d2c-9f04-e4f3987165db",
   "metadata": {},
   "source": [
    "### Push the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ef72e71-49af-4d6b-9b44-3f1dcb03bcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PUSHING MODEL TO HUGGINGFACE\n",
      "======================================================================\n",
      "Repository: kristiangnordby/cyberLabse\n",
      "Private: False\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Repository created/verified: kristiangnordby/cyberLabse\n",
      "\n",
      "üìù Creating model card...\n",
      "‚öôÔ∏è  Saving configuration...\n",
      "üèóÔ∏è  Saving model architecture...\n",
      "üíæ Preparing model checkpoint...\n",
      "\n",
      "üì§ Uploading files to HuggingFace...\n",
      "  ‚úì Uploaded: README.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Uploaded: config.json\n",
      "  ‚úì Uploaded: model_architecture.py\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417c9b87578044d195420fcf92c4a154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6598f47a0e0b4afaa1a627d4239ed62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Uploaded: model.pt\n",
      "\n",
      "======================================================================\n",
      "‚úÖ MODEL SUCCESSFULLY PUSHED TO HUGGINGFACE!\n",
      "======================================================================\n",
      "üîó View your model at: https://huggingface.co/kristiangnordby/cyberLabse\n",
      "======================================================================\n",
      "\n",
      "Model available at: https://huggingface.co/kristiangnordby/cyberLabse\n"
     ]
    }
   ],
   "source": [
    "from push_to_huggingface import push_to_huggingface\n",
    "\n",
    "with open(\"hf_token.txt\",'r') as f:\n",
    "    token = f.read()\n",
    "\n",
    "# Push your model (after training and evaluation)\n",
    "repo_url = push_to_huggingface(\n",
    "    model_path='/home/knordby/Documents/labeling/models/cyber_labseEmbeddings.pt',\n",
    "    repo_name='cyberLabse',  # Choose your repo name\n",
    "    metrics=metrics,  # From evaluate_model()\n",
    "    input_dim=x_train.shape[1],  # Your embedding dimension\n",
    "    hf_token=token,  # Your token\n",
    "    private=False  # Set True if you want private repo\n",
    ")\n",
    "\n",
    "print(f\"Model available at: {repo_url}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vanilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
